Polynomial:

Training Polynomial Regression models...
Degree = 1
Loss: 0.04633922129869461: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:53<00:00, 18.75it/s]
Train = 0.6312915212250872
Validation = 0.6390452600765594, Test = 0.6345417698716506
Degree = 2
Loss: 0.04431125521659851: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [01:43<00:00,  9.64it/s]
Train = 0.650123859925684
Validation = 0.651655032650304, Test = 0.6550326503039856
Degree = 3
Loss: 0.044432271271944046: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [02:38<00:00,  6.30it/s]
Train = 0.6448879630672222
Validation = 0.6505291600990768, Test = 0.6491781130376042



Logistic Regression:

Training Logistic Regression models...
Degree = 1
  0%|                                                                                                                                                                     | 0/1000 [00:00<?, ?it/s]/extra/adyotagupta/anaconda2/envs/SL_Final/lib/python3.7/site-packages/torch/nn/modules/container.py:117: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Loss: 2.6224677562713623: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:53<00:00, 18.71it/s]
Train = 0.18866118680328792
Validation = 0.1781130376041432, Test = 0.18509344742175185
Degree = 2
Loss: 2.223658561706543: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [01:43<00:00,  9.62it/s]
Train = 0.6085744848553091
Validation = 0.5771222697590632, Test = 0.5958117541094348
Degree = 3
Loss: 2.2364695072174072: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [02:38<00:00,  6.29it/s]
Train = 0.5987219907668055
Validation = 0.5683404638594911, Test = 0.5838775050664264



ANN:

Epoch 150/150
139/139 [==============================] - 8s 55ms/step - loss: 0.4512 - accuracy: 0.8515 - val_loss: 0.4537 - val_accuracy: 0.8460
Saving figures for Model 4...
139/139 [==============================] - 1s 4ms/step - loss: 0.4606 - accuracy: 0.8460

Epoch 150/150
139/139 [==============================] - 8s 60ms/step - loss: 0.5168 - accuracy: 0.8304 - val_loss: 0.5215 - val_accuracy: 0.8293
Saving figures for Model 3...
139/139 [==============================] - 1s 4ms/step - loss: 0.5523 - accuracy: 0.8230

Epoch 150/150
139/139 [==============================] - 7s 48ms/step - loss: 0.5114 - accuracy: 0.8289 - val_loss: 0.5049 - val_accuracy: 0.8302
Saving figures for Model 2...
139/139 [==============================] - 1s 6ms/step - loss: 0.5272 - accuracy: 0.8203
Epoch 150/150

139/139 [==============================] - 7s 50ms/step - loss: 0.1322 - accuracy: 0.9657 - val_loss: 0.2751 - val_accuracy: 0.9043
Saving figures for Model 1...
139/139 [==============================] - 1s 6ms/step - loss: 0.2844 - accuracy: 0.8996





